load("/mhome/stats/r/dp497/Dropbox/JA-DP-ST/Report Separability/simulations/aggResults/SIM19jan.RData")
N<-c(10,25,50,100)
gamma<-c(0 , 0.01 , 0.02,  0.03 , 0.04  ,0.05,  0.06  ,0.07,  0.08  ,0.09,   0.1)
for (n in 1:length(N)){
thm.power<-agg.results$CLT.P[n,,1]
emp.boot.st<-agg.results$EMP.BOOT.P[n,,1,1]
emp.boot<-agg.results$EMP.BOOT.P[n,,1,2]
par.boot<-agg.results$GAUSS.BOOT.P[n,,1,2]
par.boot.st<-agg.results$GAUSS.BOOT.P[n,,1,1]
plot(gamma,thm.power,xlab="\u0263",ylab="Empirical power",lwd=2,type='l',ylim=c(0,1),cex.lab=1.5,xlim=c(0,0.1),main=paste("N=",N[n]))
points(gamma,emp.boot.st,lwd=2,type='l',lty=2,col=4)
points(gamma,emp.boot,lwd=2,type='l',lty=5,col=5)
points(gamma,par.boot,lwd=2,type='l',lty=3,col=2)
points(gamma,par.boot.st,lwd=2,type='l',lty=4,col="orange")
abline(h=0.05,lwd=3,col=3)
}
N<-c(10,25,50,100)
gamma<-c(0 , 0.01 , 0.02,  0.03 , 0.04  ,0.05,  0.06  ,0.07,  0.08  ,0.09,   0.1)
for (n in 1:length(N)){
thm.power<-agg.results$CLT.P[n,,2]
emp.boot.st<-agg.results$EMP.BOOT.P[n,,2,1]
emp.boot<-agg.results$EMP.BOOT.P[n,,2,2]
par.boot<-agg.results$GAUSS.BOOT.P[n,,2,2]
par.boot.st<-agg.results$GAUSS.BOOT.P[n,,2,1]
plot(gamma,thm.power,xlab="\u0263",ylab="Empirical power",lwd=2,type='l',ylim=c(0,1),cex.lab=1.5,xlim=c(0,0.1),main=paste("N=",N[n]))
points(gamma,emp.boot.st,lwd=2,type='l',lty=2,col=4)
points(gamma,emp.boot,lwd=2,type='l',lty=5,col=5)
points(gamma,par.boot,lwd=2,type='l',lty=3,col=2)
points(gamma,par.boot.st,lwd=2,type='l',lty=4,col="orange")
abline(h=0.05,lwd=3,col=3)
}
remove.packages("fda")
remove.packages("shapes")
install.packages("sme")
library(sme)
help(sme)
install.packages("pedigreemm")
library(pedigreemm)
setwd("/mhome/stats/r/dp497/Dropbox/JA-DP-ST/Report Separability/AOS/R code and datasets")
load('Acoustic_Data.RData')
dim(PSD)
PSD_part1<-PSD[1:100,,]
PSD_part2<-PSD[101:219,,]
Speaker_info<-read.table('Info_Acoustic_Data.txt',header=T)
attach(Speaker_info)
head(Speaker_info)
dim(Speaker_info)[1]
save(PSD_part1,file="Acoustic_Data_part1.RData")
save(PSD_part2,file="Acoustic_Data_part2.RData")
source('bootstrap_tests_rectangles.R')
Speaker_info<-read.table('Info_Acoustic_Data.txt',header=T)
source('bootstrap_tests_rectangles.R')
# import infromation about language and word for the recorded sounds
Speaker_info<-read.table('Info_Acoustic_Data.txt',header=T)
# import the smoothed and aligned spectrograms
load('Acoustic_Data_part1.RData')
load('Acoustic_Data_part2.RData')
PSD<-array(NA,c(dim(Speaker_info)[1],dim(PSD_part1)[2],dim(PSD_part1)[2]))
PSD[1:100,,]<-PSD_part1
dim(PSD)
port the test function
source('bootstrap_tests_rectangles.R')
# import infromation about language and word for the recorded sounds
Speaker_info<-read.table('Info_Acoustic_Data.txt',header=T)
# import the smoothed and aligned spectrograms
load('Acoustic_Data_part1.RData')
load('Acoustic_Data_part2.RData')
PSD<-array(NA,c(dim(Speaker_info)[1],dim(PSD_part1)[2],dim(PSD_part1)[3]))
PSD[1:100,,]<-PSD_part1
PSD[101:dim(Speaker_info)[1],,]<-PSD_part2
image.plot(PSD[1,,])
image(PSD[1,,])
image(PSD[100,,])
image(PSD[101,,])
image(PSD[201,,])
attach(Speaker_info)
D<-array(0,dim(PSD))
for ( i in 1:10){
Fr1<-which(language=='French'& digit==i)
I1<-which(language=='Italian'& digit==i)
P1<-which(language=='Portuguese'& digit==i)
SA1<-which(language=='American_Spanish'& digit==i)
SI1<-which(language=='Iberian_Spanish'& digit==i)
M<-apply(PSD[Fr1,,],c(2,3),mean)
for (k in Fr1){
D[k,,]<-PSD[k,,]-M
}
M<-apply(PSD[I1,,],c(2,3),mean)
for (k in I1){
D[k,,]<-PSD[k,,]-M
}
M<-apply(PSD[P1,,],c(2,3),mean)
for (k in P1){
D[k,,]<-PSD[k,,]-M
}
M<-apply(PSD[SA1,,],c(2,3),mean)
for (k in SA1){
D[k,,]<-PSD[k,,]-M
}
M<-apply(PSD[SI1,,],c(2,3),mean)
for (k in SI1){
D[k,,]<-PSD[k,,]-M
}
}
Fr<-which(language=='French')
I<-which(language=='Italian')
P<-which(language=='Portuguese')
SA<-which(language=='American_Spanish')
SI<-which(language=='Iberian_Spanish')
L1<-1 # number of eigenfunctions to be used in the first direction
L2<-1 # number of eigenfunctions to be used in the second direction
emp.boot.test(D[Fr,,],L1,L2,B=10) # French
emp.boot.test(D[I,,],L1,L2,B=1000) # Italian
setwd("/mhome/stats/r/dp497/Dropbox/JA-DP/Phylogenetic paper/Phonetic projection/Code and Data")
library(R.matlab)
library(fields)
library(rgl)
#############################################################################
########   This script implements the analysis of acoustic phonetic data ####
########           described in Pigoli et al., 2015                      ####
########                                                                 ####
#############################################################################
source('acoustic_functions.R')
# Import data from Matlab save files
#Data<-readMat('WarpedPSD.mat')
# Import data from R workspace
load('WarpedPSD.RData')
Data2<-array(0,c(219,81,100))
for (i in 1:219){
Data2[i,,]<-Data[[1]][i][[1]]
}
# Import speaker information
Speaker_info<-read.table('SpeakerInfo.txt',header=T)
attach(Speaker_info)
# Estimation of word means
MFr<-array(NA,dim(Data2))
MI<-array(NA,dim(Data2))
MP<-array(NA,dim(Data2))
MSA<-array(NA,dim(Data2))
MSI<-array(NA,dim(Data2))
for ( i in 1:10){
Fr1<-which(language=='French'& digit==i)
I1<-which(language=='Italian'& digit==i)
P1<-which(language=='Portuguese'& digit==i)
SA1<-which(language=='American_Spanish'& digit==i)
SI1<-which(language=='Iberian_Spanish'& digit==i)
MFr[i,,]<-apply(Data2[Fr1,,],c(2,3),mean)
MI[i,,]<-apply(Data2[I1,,],c(2,3),mean)
MP[i,,]<-apply(Data2[P1,,],c(2,3),mean)
MSA[i,,]<-apply(Data2[SA1,,],c(2,3),mean)
MSI[i,,]<-apply(Data2[SI1,,],c(2,3),mean)
}
### Estimation of the separable language covariances
D<-array(0,dim(Data2))
for ( i in 1:10){
Fr1<-which(language=='French'& digit==i)
I1<-which(language=='Italian'& digit==i)
P1<-which(language=='Portuguese'& digit==i)
SA1<-which(language=='American_Spanish'& digit==i)
SI1<-which(language=='Iberian_Spanish'& digit==i)
M<-apply(Data2[Fr1,,],c(2,3),mean)
for (k in Fr1){
D[k,,]<-Data2[k,,]-M
}
M<-apply(Data2[I1,,],c(2,3),mean)
for (k in I1){
D[k,,]<-Data2[k,,]-M
}
M<-apply(Data2[P1,,],c(2,3),mean)
for (k in P1){
D[k,,]<-Data2[k,,]-M
}
M<-apply(Data2[SA1,,],c(2,3),mean)
for (k in SA1){
D[k,,]<-Data2[k,,]-M
}
M<-apply(Data2[SI1,,],c(2,3),mean)
for (k in SI1){
D[k,,]<-Data2[k,,]-M
}
}
Fr<-which(language=='French')
I<-which(language=='Italian')
P<-which(language=='Portuguese')
SA<-which(language=='American_Spanish')
SI<-which(language=='Iberian_Spanish')
CFT<-sep.cov(D[Fr,,])[[1]]
CPT<-sep.cov(D[P,,])[[1]]
CIT<-sep.cov(D[I,,])[[1]]
CSAT<-sep.cov(D[SA,,])[[1]]
CSIT<-sep.cov(D[SI,,])[[1]]
CFW<-sep.cov(D[Fr,,])[[2]]
CPW<-sep.cov(D[P,,])[[2]]
CIW<-sep.cov(D[I,,])[[2]]
CSAW<-sep.cov(D[SA,,])[[2]]
CSIW<-sep.cov(D[SI,,])[[2]]
l1<-"French"
l2<-"Portuguese"
# Select the parameters of the language
C1<-CFT
C2<-CPT
T1<-CFW
T2<-CPW
dig<-5
L1<-which(language==l1 & digit==dig)
L2<-which(language==l2 & digit==dig)
M1<-apply(Data2[L1,,],c(2,3),mean)
M2<-apply(Data2[L2,,],c(2,3),mean)
# Grid for the interpolation (values between 0 and 1) or extrapolation (<0 or >1)
weights<-c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)
spk1<-1
spk2<-2
Res1<-Data2[L1[spk1],,]-M1
Res2<-Data2[L2[spk2],,]-M1
Spect_path<-list()
for ( h in 1:length(weights)){
w<-weights[h]
############## Frequency covariance ###################
SI<-sqrtM(C1)
SA<-sqrtM(C2)
C<-t(SA)%*%SI
SVD<-svd(C)
R<-SVD$u%*%t(SVD$v)
C3<-(SI+w*(SA-SI%*%R))%*%t(SI+w*(SA-SI%*%R))
############## Time covariance ###################
SI<-sqrtM(T1)
SA<-sqrtM(T2)
C<-t(SA)%*%SI
SVD<-svd(C)
R<-SVD$u%*%t(SVD$v)
T3<-(SI+w*(SA-SI%*%R))%*%t(SI+w*(SA-SI%*%R))
############# Means interpolation ##############
M<-(1-w)*M1+w*M2
############ Residual standardization #########
Res1x<-solve(sqrtM(C1))%*%Res1%*%(solve(sqrtM(T1)))
Res2x<-solve(sqrtM(C2))%*%Res2%*%(solve(sqrtM(T2)))
Resx<-(1-w)*Res1x+w*Res2x
################################################
# Interpolation
Y<-(sqrtM(C3))%*%Resx%*%(sqrtM(T3))+M
Spect_path<-c(Spect_path,list(Y))
}
# save the interpolated path in a matlab file for sound reconstruction.
writeMat("Spect_path.mat",Spect_path1=Spect_path[[1]],Spect_path2=Spect_path[[2]],Spect_path3=Spect_path[[3]],Spect_path4=Spect_path[[4]],Spect_path5=Spect_path[[5]],Spect_path6=Spect_path[[6]],Spect_path7=Spect_path[[7]],Spect_path8=Spect_path[[8]],Spect_path9=Spect_path[[9]],Spect_path10=Spect_path[[10]],Spect_path11=Spect_path[[11]])
# Speaker
spk<-1
# Residual for the speaker
Res1<-Data2[L1[spk],,]-M1
Spect_proj<-list()
for ( h in 1:length(weights)){
w<-weights[h]
############## Frequency covariance ###################
SI<-sqrtM(C1)
SA<-sqrtM(C2)
C<-t(SA)%*%SI
SVD<-svd(C)
R<-SVD$u%*%t(SVD$v)
C3<-(SI+w*(SA-SI%*%R))%*%t(SI+w*(SA-SI%*%R))
############## Time covariance ###################
SI<-sqrtM(T1)
SA<-sqrtM(T2)
C<-t(SA)%*%SI
SVD<-svd(C)
R<-SVD$u%*%t(SVD$v)
T3<-(SI+w*(SA-SI%*%R))%*%t(SI+w*(SA-SI%*%R))
############# Means interpolation ##############
M<-(1-w)*M1+w*M2
################################################
# Interpolation
Y<-(sqrtM(C3)%*%solve(sqrtM(C1)))%*%Res1%*%(solve(sqrtM(T1))%*%sqrtM(T3))+M
Spect_proj<-c(Spect_proj,list(Y))
}
writeMat("Spect_proj.mat",Spect_proj1=Spect_proj[[1]],Spect_proj2=Spect_proj[[2]],Spect_proj3=Spect_proj[[3]],Spect_proj4=Spect_proj[[4]],Spect_proj5=Spect_proj[[5]],Spect_proj6=Spect_proj[[6]],Spect_proj7=Spect_proj[[7]],Spect_proj8=Spect_proj[[8]],Spect_proj9=Spect_proj[[9]],Spect_proj10=Spect_proj[[10]],Spect_proj11=Spect_proj[[11]])
source('../Code and Data/acoustic_functions.R')
Sounds<-readMat('../Code and Data/PrunedLanguageDataset.mat')
library(R.matlab)
library(fields)
library(rgl)
library(fda)
Sounds<-readMat('../Code and Data/PrunedLanguageDataset.mat')
plot(Sounds[[136]],type='l',main=names(Sounds)[136],col=4)
plot(Sounds[[100]],type='l',main=names(Sounds)[100],col=4)
language<-rep(NA, length(Sounds))
digit<-rep(NA, length(Sounds))
gender<-rep(NA, length(Sounds))
sounds.spec <- vector("list",length(Sounds))
for (k in 1:length(Sounds)){
S<-specgram(Sounds[[k]], n=wn, Fs=16000, window=gausswin(wn))
A<-abs(S$S)^2
A<-A/max(A)
A = pmax(A, 10^(-16))
sounds.spec[[k]]<-list(power=10*log(A), phase=Arg(S$S))
header<-unlist(strsplit(names(Sounds)[k], "[.]"))
language[k]<-header[1]
digit[k]<-as.double(header[3])
gender[k]<-header[4]
}
Speaker_info<-data.frame(language=language,digit=digit,gender=gender)
source('../Code and Data/acoustic_functions.R')
language<-rep(NA, length(Sounds))
digit<-rep(NA, length(Sounds))
gender<-rep(NA, length(Sounds))
sounds.spec <- vector("list",length(Sounds))
for (k in 1:length(Sounds)){
S<-specgram(Sounds[[k]], n=wn, Fs=16000, window=gausswin(wn))
A<-abs(S$S)^2
A<-A/max(A)
A = pmax(A, 10^(-16))
sounds.spec[[k]]<-list(power=10*log(A), phase=Arg(S$S))
header<-unlist(strsplit(names(Sounds)[k], "[.]"))
language[k]<-header[1]
digit[k]<-as.double(header[3])
gender[k]<-header[4]
}
Speaker_info<-data.frame(language=language,digit=digit,gender=gender)
library(signal)
language<-rep(NA, length(Sounds))
digit<-rep(NA, length(Sounds))
gender<-rep(NA, length(Sounds))
sounds.spec <- vector("list",length(Sounds))
for (k in 1:length(Sounds)){
S<-specgram(Sounds[[k]], n=wn, Fs=16000, window=gausswin(wn))
A<-abs(S$S)^2
A<-A/max(A)
A = pmax(A, 10^(-16))
sounds.spec[[k]]<-list(power=10*log(A), phase=Arg(S$S))
header<-unlist(strsplit(names(Sounds)[k], "[.]"))
language[k]<-header[1]
digit[k]<-as.double(header[3])
gender[k]<-header[4]
}
Speaker_info<-data.frame(language=language,digit=digit,gender=gender)
wn<-160
rate<-16000
#plot(Sounds[[136]],type='l',main=names(Sounds)[136],col=4)
plot(Sounds[[100]],type='l',main=names(Sounds)[100],col=4)
## extract sounds and compute spectrograms (takes some time) (it takes too much
## memory to load first all the sounds into memory, and then doing the computations
#sounds.spec <- sapply(1:5, function(j){
language<-rep(NA, length(Sounds))
digit<-rep(NA, length(Sounds))
gender<-rep(NA, length(Sounds))
sounds.spec <- vector("list",length(Sounds))
for (k in 1:length(Sounds)){
S<-specgram(Sounds[[k]], n=wn, Fs=16000, window=gausswin(wn))
A<-abs(S$S)^2
A<-A/max(A)
A = pmax(A, 10^(-16))
sounds.spec[[k]]<-list(power=10*log(A), phase=Arg(S$S))
header<-unlist(strsplit(names(Sounds)[k], "[.]"))
language[k]<-header[1]
digit[k]<-as.double(header[3])
gender[k]<-header[4]
}
Speaker_info<-data.frame(language=language,digit=digit,gender=gender)
image(sounds.spec[[1]]$power)
image(sounds.spec[[1]]$phase)
nsounds <- length(sounds.spec)
nfreq<-dim(sounds.spec[[1]]$power)[1]
######## interpolate on common grid ##########
eq.grid<-seq(0,1,len=100)
dim(sounds.spec[[1]])
dim(sounds.spec[[1]]$power)
dim(sounds.spec[[2]]$power)
load("SmoothPDS.RData")
load("SVRF_WarpedPSD.RData")
load("/local/scratch/public/dp497/Dropbox/Dropbox/JA-DP/Phylogenetic paper/Code and Data/SVRF_WarpedPSD_SuppMat.RData")
image(Data2[1,,])
Data2[1,1,1]
Data2[1,1,2]
P1<-which(language=='FR'& digit==1)
GP<-Data2[P1[1],,]
#GP<-MFr[1,,]
brk<-seq(min(GP),max(GP),len=60)
#brk<-seq(-0.01,0.05,len=60)
color = tim.colors(length(brk)-1)
par3d(cex=2)
zcol  = cut(GP, brk)
time<-seq(0,1,len=dim(GP)[2])
freq<-seq(0,8,len=80)
persp3d(freq,time,GP,xlab="",ylab="",zlab="",cex.lab=1.5,lwd=2,cex.axis=1.5,col=color[zcol])
P1<-which(language=='FR'& digit==1)
GP<-Data2[P1[1],,]
#GP<-MFr[1,,]
brk<-seq(min(GP),max(GP),len=60)
#brk<-seq(-0.01,0.05,len=60)
color = tim.colors(length(brk)-1)
zcol  = cut(GP, brk)
time<-seq(0,1,len=dim(GP)[2])
freq<-seq(0,8,len=80)
persp3d(freq,time,GP,xlab="",ylab="",zlab="",cex.lab=1.5,lwd=2,cex.axis=1.5,col=color[zcol])
image.plot(time,freq,t(GP),main="French speaker, word 'un'",xlab="Time (standardized)",ylab="Frequency (kHz)",cex.lab=1.5,cex.axis=1.5,cex.main=1.5)
par(mar=c(5,6,4,2))
image.plot(freq,freq,t(CFT),main="French",xlab="Frequency (kHz)",ylab="Frequency (kHz)",cex.lab=1.5,cex.axis=1.5,cex.main=1.5)
image.plot(freq,freq,t(CPT),main="Portuguese",xlab="Frequency (kHz)",ylab="Frequency (kHz)",cex.lab=1.5,cex.axis=1.5,cex.main=1.5)
image.plot(freq,freq,t(CIT),main="Italian",xlab="Frequency (kHz)",ylab="Frequency (kHz)",cex.lab=1.5,cex.axis=1.5,cex.main=1.5)
image.plot(freq,freq,t(CSAT),main="American Spanish",xlab="Frequency (kHz)",ylab="Frequency (kHz)",cex.lab=1.5,cex.axis=1.5,cex.main=1.5)
image.plot(freq,freq,t(CSIT),main="Castilian Spanish",xlab="Frequency (kHz)",ylab="Frequency (kHz)",cex.lab=1.5,cex.axis=1.5,cex.main=1.5)
Spectro<-Data2[1,,]
image(Spectro)
S<-specgram(Sounds$FR.F.5.F.c, n=wn, Fs=16000, window=gausswin(wn))
phase<-Arg(S$S)
output<-c()
PSD<-matrix(NA,dim(phase)[1],dim(phase)[2])
for (j in 1:dim(Spectro[[k]])[1]){
PSD[j,]<-approx(time,Spectro[[k]][j,],xout=seq(0,1,len=dim(phase)[2]))$y
}
out<-sound_from_spectrogram(PSD,phase,rate,bit=16,wn)
source('../Code and Data/acoustic_functions.R')
PSD<-matrix(NA,dim(phase)[1],dim(phase)[2])
for (j in 1:dim(Spectro[[k]])[1]){
PSD[j,]<-approx(time,Spectro[[k]][j,],xout=seq(0,1,len=dim(phase)[2]))$y
}
out<-sound_from_spectrogram(PSD,phase,rate,bit=16,wn)
PSD<-matrix(NA,dim(phase)[1],dim(phase)[2])
for (j in 1:dim(Spectro)[1]){
PSD[j,]<-approx(time,Spectro[[k]][j,],xout=seq(0,1,len=dim(phase)[2]))$y
}
out<-sound_from_spectrogram(PSD,phase,rate,bit=16,wn)
Spectro<-Data2[1,,]
### recover phase info ####
#Sounds<-readMat('../Code and Data/PrunedLanguageDataset.mat')
wn<-160
rate<-16000
S<-specgram(Sounds$FR.F.5.F.c, n=wn, Fs=16000, window=gausswin(wn))
phase<-Arg(S$S)
PSD<-matrix(NA,dim(phase)[1],dim(phase)[2])
for (j in 1:dim(Spectro)[1]){
PSD[j,]<-approx(time,Spectro[j,],xout=seq(0,1,len=dim(phase)[2]))$y
}
out<-sound_from_spectrogram(PSD,phase,rate,bit=16,wn)
output<-Wave(out,right = numeric(0), samp.rate = rate, bit = 16)
plot(out)
plot(Sounds[[1]])
plot(Sounds[[1]],type='l')
writeWave(out,filename ="sound_example.wav")
writeWave(Sounds[[1]],filename ="sound_example.wav")
output<-Wave(Sounds[[1]],right = numeric(0), samp.rate = rate, bit = 16)
writeWave(output,filename ="sound_example.wav")
output<-normalize(Wave(Sounds[[1]]*10,right = numeric(0), samp.rate = rate, bit = 16))
writeWave(output,filename ="sound_example.wav")
plot(output)
output<-normalize(Wave(Sounds[[1]]*1000,right = numeric(0), samp.rate = rate, bit = 16))
writeWave(output,filename ="sound_example.wav")
plot(output)
out<-sound_from_spectrogram(PSD,phase,rate,bit=16,wn)
plot(out)
output<-normalize(Wave(Sounds[[1]]*20000,right = numeric(0), samp.rate = rate, bit = 16))
writeWave(output,filename ="sound_example.wav")
plot(output)
output<-Wave(Sounds[[1]]*20000,right = numeric(0), samp.rate = rate, bit = 16)
writeWave(output,filename ="sound_example.wav")
plot(output)
